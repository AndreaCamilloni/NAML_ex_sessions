{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "16_Newton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZCDNUgw0nI3"
      },
      "source": [
        "# Newton method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJcJCwFhc8cs"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "\n",
        "# We enable double precision in JAX\n",
        "from jax.config import config\n",
        "config.update(\"jax_enable_x64\", True)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qkdJdGg1AP1"
      },
      "source": [
        "We consider a random matrix $A \\in \\mathbb{R}^{n\\times n}$, with $n = 100$ and a random vector $\\mathbf{x}_{\\text{ex}} \\in \\mathbb{R}^n$.\n",
        "We define then $\\mathbf{b} = A \\, \\mathbf{x}_{\\text{ex}}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0h8ihCddDPf"
      },
      "source": [
        "n = 100\n",
        "\n",
        "np.random.seed(0)\n",
        "A = np.random.randn(n,n)\n",
        "x_ex = np.random.randn(n)\n",
        "b = A @ x_ex"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UanVhF4xAVoX"
      },
      "source": [
        "Define the loss function\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\mathbf{x}) = \\| \\mathbf{b} - A \\, \\mathbf{x} \\|_2^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(x):\n",
        "  return np.sum((b - A@x)**2)"
      ],
      "metadata": {
        "id": "69LsTWE_f0Ar"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAZ9XGaiAs3X"
      },
      "source": [
        "By using the `jax` library, implement and compile functins returning the gradient ($\\nabla \\mathcal{J}(\\mathbf{x})$) and the hessian ($\\nabla^2 \\mathcal{J}(\\mathbf{x})$) of the loss function (*Hint*: use the `jacrev` or the `jacfwd`) function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KflmuLXld2T4"
      },
      "source": [
        "grad = jax.grad(loss)\n",
        "#hess = jax.jacrev(grad) #reverse automatic diff: convenient when we have many inputs\n",
        "hess = jax.jacfwd(grad) #forward automatic diff: convenient when we have many outputs\n",
        "\n",
        "\n",
        "loss_jit = jax.jit(loss)\n",
        "grad_jit = jax.jit(grad)\n",
        "hess_jit = jax.jit(hess)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSMg8ocDBndO"
      },
      "source": [
        "Check that the results are correct (up to machine precision)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZulGRQ1efFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a21a74-ca5e-4419-df87-c423094c216a"
      },
      "source": [
        "np.random.seed(0)\n",
        "x_guess = np.random.randn(n)\n",
        "\n",
        "G_ad = grad_jit(x_guess) #using the gradient define above\n",
        "G_ex = 2 * A.T @ (A @ x_guess - b) #using the formulas\n",
        "print(np.linalg.norm(G_ad - G_ex))\n",
        "\n",
        "H_ad = hess_jit(x_guess)\n",
        "H_ex = 2 * A.T @ A\n",
        "print(np.linalg.norm(H_ad - H_ex))\n",
        "\n",
        "#we get in both ways a small error"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1386862836549995e-12\n",
            "5.159031549839615e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-gA_kKPB2SV"
      },
      "source": [
        "Exploit the formula\n",
        "$$\n",
        "\\nabla^2 \\mathcal{J}(\\mathbf{x}) \\mathbf{v} = \\nabla_{\\mathbf{x}} \\phi(\\mathbf{x}, \\mathbf{v})\n",
        "$$\n",
        "where \n",
        "$$\n",
        "\\phi(\\mathbf{x}, \\mathbf{v}) := \\nabla \\mathcal{J}(\\mathbf{x}) \\cdot \\mathbf{v}\n",
        "$$\n",
        "to write an optimized function returning the hessian-vector-product\n",
        "$$\n",
        "(\\mathbf{x}, \\mathbf{v}) \\mapsto \\nabla^2 \\mathcal{J}(\\mathbf{x}) \\mathbf{v}.\n",
        "$$\n",
        "Compare the computational performance w.r.t. the full hessian computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9969dU4kc6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e07174-dee6-4930-ab74-67881e20ca5e"
      },
      "source": [
        "np.random.seed(1)\n",
        "v = np.random.randn(n)\n",
        "\n",
        "hvp_basic = lambda x, v: hess(x) @ v\n",
        "gvp = lambda x,v: jnp.vdot(grad(x), v)\n",
        "hvp = jax.grad(gvp, argnums = 0 )\n",
        "\n",
        "hvp_basic_jit = jax.jit(hvp_basic)\n",
        "hvp_jit = jax.jit(hvp)\n",
        "\n",
        "Hv_ad = hvp_jit(x_guess, v)\n",
        "Hv_ex = H_ex @ v\n",
        "print(np.linalg.norm(Hv_ad - Hv_ex))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2715738311164232e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsA4eUnuj3ju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e74dcc0a-3591-40c9-b744-e1c1b9c11850"
      },
      "source": [
        "%timeit hvp_basic_jit(x_guess, v)\n",
        "%timeit hvp_jit(x_guess, v)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 293.25 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 5: 334 µs per loop\n",
            "The slowest run took 10.20 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100000 loops, best of 5: 8.08 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TagmrdjG4Ww4"
      },
      "source": [
        "Implement the Newton method for the minimization of the loss function $\\mathcal{L}$. Set a maximim number of 100 iterations and a tolerance on the increment norm of $\\epsilon = 10^{-8}$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "eps = 1e-8\n",
        "\n",
        "x = x_guess.copy()\n",
        "\n",
        "hist= [loss_jit(x)]\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  G = grad_jit(x)\n",
        "  H = hess_jit(x)\n",
        "  incr = np.linalg.solve(H, -G)\n",
        "  x += incr\n",
        "  hist.append(loss_jit(x))\n",
        "\n",
        "  if(np.linalg.norm(incr)<eps): break\n",
        "\n",
        "error =  (np.linalg.norm(x - x_ex)/np.linalg.norm(x_ex))\n",
        "print('Epochs %d' % (e +1))\n",
        "print('Error %1.3e' % error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgcTUktFjfiN",
        "outputId": "3c7500c0-b2a1-4c8f-d6be-7bbbd9c01838"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs 2\n",
            "Error 6.275e-15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNL7303C4oTL"
      },
      "source": [
        "Repeat the optimization loop for the loss function\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\mathbf{x}) = \\| \\mathbf{b} - A \\, \\mathbf{x} \\|_4^4\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(x):\n",
        "  return np.sum((b - A@x)**4)"
      ],
      "metadata": {
        "id": "cSx2gp4NnG1_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad = jax.grad(loss)\n",
        "#hess = jax.jacrev(grad) #reverse automatic diff: convenient when we have many inputs\n",
        "hess = jax.jacfwd(grad) #forward automatic diff: convenient when we have many outputs\n",
        "\n",
        "\n",
        "loss_jit = jax.jit(loss)\n",
        "grad_jit = jax.jit(grad)\n",
        "hess_jit = jax.jit(hess)"
      ],
      "metadata": {
        "id": "TxKWsBjfnQRF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "eps = 1e-8\n",
        "\n",
        "x = x_guess.copy()\n",
        "\n",
        "hist= [loss_jit(x)]\n",
        "\n",
        "for e in range(num_epochs):\n",
        "  G = grad_jit(x)\n",
        "  H = hess_jit(x)\n",
        "  incr = np.linalg.solve(H, -G)\n",
        "  x += incr\n",
        "  hist.append(loss_jit(x))\n",
        "\n",
        "  if(np.linalg.norm(incr)<eps): break\n",
        "\n",
        "error =  (np.linalg.norm(x - x_ex)/np.linalg.norm(x_ex))\n",
        "print('Epochs %d' % (e +1))\n",
        "print('Error %1.3e' % error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgm7MIYjnM9r",
        "outputId": "2ec803db-457f-4aa6-d630-e7c0570534ee"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs 51\n",
            "Error 1.657e-09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.semilogy(hist, 'o-')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "xnkm_l0dnYeX",
        "outputId": "2a40041c-a888-43f5-99f5-a2cb85dbcabb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efd644a3690>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}